{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_sets():\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_features = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "    train_features = torch.functional.F.avg_pool2d(train_features, kernel_size = 2)\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_features = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "    test_features = torch.functional.F.avg_pool2d(test_features, kernel_size = 2)\n",
    "\n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_features, train_target, test_features, test_target = generate_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 14, 14]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 14, 14]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "train_perm = torch.randperm(train_features.size(0))\n",
    "idx = train_perm[:data_size]\n",
    "train_features = train_features[idx].reshape([data_size, train_features.size(2)**2])\n",
    "train_target = train_target[idx]\n",
    "\n",
    "test_perm = torch.randperm(test_features.size(0))\n",
    "idx = test_perm[:data_size]\n",
    "test_features = test_features[idx].reshape([data_size, test_features.size(2)**2])\n",
    "test_target = test_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196]) torch.Size([1000])\n",
      "torch.Size([1000, 196]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def normalize(tensor):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return tensor.sub_(mean).div_(std)\n",
    "\n",
    "normalize(train_features)\n",
    "normalize(test_features)\n",
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_features[i].reshape([14, 14]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_target[i]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.ReLU = torch.nn.ReLU() \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = torch.nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(self.ReLU(self.fc1(x)))\n",
    "        x = self.ReLU(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, train_features_, train_target_, criterion_, optimizer_, num_epochs_, batch_size_, learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(train_features_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = train_features_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, train_features_, train_target_))\n",
    "        test_error.append(test_accuracy(model_, test_features, test_target))\n",
    "    # getting end time and training time\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    print('Loss: {:.4f} on final epoch: {}. Train error: {:.5f}%, Test error: {:.5f}%'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_features_, my_test_target_):\n",
    "    outputs = model_(my_test_features_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    count_errors = (predictions.long() != my_test_target_.long()).sum().item()\n",
    "    return count_errors / my_test_features_.size(0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homemade framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_homemade_model(model_, num_epochs_, train_features_np_, train_target_np_, batch_size_):\n",
    "    start_time = datetime.datetime.now()\n",
    "    # Convert train_target to one hot encoding\n",
    "    train_target_one_hot = NN.convert_to_one_hot_labels(train_features_np_, train_target_np_)\n",
    "\n",
    "    NN.print_current_results(0, model_, train_features_np_, train_target_np_, test_features_np, test_target_np, 0, prefix = \"Before training: \")\n",
    "    test_results = []\n",
    "    for epochs in range(0, num_epochs_):\n",
    "        loss_sum = 0\n",
    "        test_results.append(NN.get_inferences(Model, test_features_np))\n",
    "        for b in range(train_features.shape[0] // batch_size):\n",
    "            output = model_.forward(train_features_np_[list(range(b * batch_size_, (b+1) * batch_size_))])\n",
    "            loss = model_.backward(train_target_one_hot[list(range(b * batch_size_, (b+1) * batch_size_))], output)\n",
    "            loss_sum = loss_sum + loss.item()\n",
    "        if epochs % 30 == 0:\n",
    "            NN.print_current_results(epochs + 1, model_, train_features_np_, train_target_np_, test_features_np, test_target_np, loss_sum)\n",
    "\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('\\nTraining time: {}'.format(training_time))\n",
    "    NN.print_current_results(epochs, Model, train_features_np, train_target_np, test_features_np, test_target_np, loss_sum, prefix = \"After training: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 100\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 10\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:09.570388\n",
      "Loss: 0.0326 on final epoch: 100. Train error: 0.00000%, Test error: 11.50000%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class, p_dropout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, train_features, train_target, criterion, optimizer, num_epochs, batch_size, LRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train homemade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: \n",
      "\tLinear layer shape: [196, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 10]\n",
      "\tLeakyReLU activation\n",
      "\tMSE\n",
      "Before training: Epoch: 0, Train Error: 88.5000%,        Test Error: 88.1000%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 90.0000%,        Test Error: 88.6000%, Loss  1273.6170\n",
      "Epoch: 31, Train Error: 1.6000%,        Test Error: 11.8000%, Loss  25.3638\n",
      "Epoch: 61, Train Error: 1.2000%,        Test Error: 11.7000%, Loss  28.4304\n",
      "Epoch: 91, Train Error: 0.8000%,        Test Error: 11.8000%, Loss  11.1132\n",
      "\n",
      "Training time: 0:00:03.054394\n",
      "After training: Epoch: 99, Train Error: 0.8000%,        Test Error: 11.4000%, Loss  10.4300\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy array\n",
    "train_features_np, train_target_np = train_features.numpy(), train_target.numpy()\n",
    "test_features_np, test_target_np = test_features.numpy(), test_target.numpy()\n",
    "\n",
    "# Build the model\n",
    "Model = NN.Sequential([NN.Linear(input_size, hidden_size), NN.LeakyReLU(), NN.Linear(hidden_size, num_class), NN.LeakyReLU()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=False)\n",
    "\n",
    "train_homemade_model(Model, num_epochs, train_features_np, train_target_np, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
