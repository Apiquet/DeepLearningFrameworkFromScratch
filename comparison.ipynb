{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_sets():\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_features = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "    train_features = torch.functional.F.avg_pool2d(train_features, kernel_size = 2)\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_features = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "    test_features = torch.functional.F.avg_pool2d(test_features, kernel_size = 2)\n",
    "\n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "train_features, train_target, test_features, test_target = generate_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 14, 14]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 14, 14]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "train_perm = torch.randperm(train_features.size(0))\n",
    "idx = train_perm[:data_size]\n",
    "train_features = train_features[idx].reshape([data_size, train_features.size(2)**2])\n",
    "train_target = train_target[idx]\n",
    "\n",
    "test_perm = torch.randperm(test_features.size(0))\n",
    "idx = test_perm[:data_size]\n",
    "test_features = test_features[idx].reshape([data_size, test_features.size(2)**2])\n",
    "test_target = test_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196]) torch.Size([1000])\n",
      "torch.Size([1000, 196]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def normalize(tensor):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return tensor.sub_(mean).div_(std)\n",
    "\n",
    "normalize(train_features)\n",
    "normalize(test_features)\n",
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_features[i].reshape([14, 14]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_target[i]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.ReLU = torch.nn.ReLU() \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = torch.nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.ReLU(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, train_features_, train_target_, criterion_, optimizer_, num_epochs_, batch_size_, learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(train_features_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = train_features_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, train_features_, train_target_))\n",
    "        test_error.append(test_accuracy(model_, test_features, test_target))\n",
    "    # getting end time and training time\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    print('Loss: {:.4f} on final epoch: {}. Train error: {:.5f}%, Test error: {:.5f}%'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_features_, my_test_target_):\n",
    "    outputs = model_(my_test_features_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    count_errors = (predictions.long() != my_test_target_.long()).sum().item()\n",
    "    return count_errors / my_test_features_.size(0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homemade framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 200\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 10\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:25.695020\n",
      "Loss: 1.6799 on final epoch: 200. Train error: 11.00000%, Test error: 19.00000%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class, p_dropout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, train_features, train_target, criterion, optimizer, num_epochs, batch_size, LRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train homemade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: \n",
      "\tLinear layer shape: [196, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 10]\n",
      "\tSoftmax function\n",
      "\tMSE\n",
      "Before training: Epoch: 0, Train Error: 90.0000%,        Test Error: 90.2000%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 66.9000%,        Test Error: 72.3000%, Loss  88.3052\n",
      "Epoch: 31, Train Error: 7.1000%,        Test Error: 12.6000%, Loss  10.7886\n",
      "Epoch: 61, Train Error: 5.1000%,        Test Error: 12.4000%, Loss  6.1759\n",
      "Epoch: 91, Train Error: 2.7000%,        Test Error: 13.0000%, Loss  4.0603\n",
      "Epoch: 121, Train Error: 1.6000%,        Test Error: 11.2000%, Loss  2.6945\n",
      "Epoch: 151, Train Error: 0.4000%,        Test Error: 10.5000%, Loss  4.2094\n",
      "Epoch: 181, Train Error: 0.6000%,        Test Error: 10.4000%, Loss  0.8877\n",
      "\n",
      "Training time: 0:00:10.208378\n",
      "After training: Epoch: 199, Train Error: 0.4000%,        Test Error: 10.5000%, Loss  0.8541\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy array\n",
    "train_features_np, train_target_np = train_features.numpy(), train_target.numpy()\n",
    "test_features_np, test_target_np = test_features.numpy(), test_target.numpy()\n",
    "\n",
    "# Build the model\n",
    "Model = NN.Sequential([NN.Linear(input_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=False)\n",
    "\n",
    "NN.train_homemade_model(Model, num_epochs, train_features_np, train_target_np, test_features_np, test_target_np, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
