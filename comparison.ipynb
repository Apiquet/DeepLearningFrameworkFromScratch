{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_sets():\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_features = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "    train_features = torch.functional.F.avg_pool2d(train_features, kernel_size = 2)\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_features = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "    test_features = torch.functional.F.avg_pool2d(test_features, kernel_size = 2)\n",
    "\n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_features, train_target, test_features, test_target = generate_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 14, 14]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 14, 14]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "train_perm = torch.randperm(train_features.size(0))\n",
    "idx = train_perm[:data_size]\n",
    "train_features = train_features[idx].reshape([data_size, train_features.size(2)**2])\n",
    "train_target = train_target[idx]\n",
    "\n",
    "test_perm = torch.randperm(test_features.size(0))\n",
    "idx = test_perm[:data_size]\n",
    "test_features = test_features[idx].reshape([data_size, test_features.size(2)**2])\n",
    "test_target = test_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196]) torch.Size([1000])\n",
      "torch.Size([1000, 196]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def normalize(tensor):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return tensor.sub_(mean).div_(std)\n",
    "\n",
    "normalize(train_features)\n",
    "normalize(test_features)\n",
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_features[i].reshape([14, 14]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_target[i]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.ReLU = torch.nn.ReLU() \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = torch.nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.ReLU(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, train_features_, train_target_, criterion_, optimizer_, num_epochs_, batch_size_, learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(train_features_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = train_features_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, train_features_, train_target_))\n",
    "        test_error.append(test_accuracy(model_, test_features, test_target))\n",
    "    # getting end time and training time\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    print('Loss: {:.4f} on final epoch: {}. Train error: {:.5f}%, Test error: {:.5f}%'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_features_, my_test_target_):\n",
    "    outputs = model_(my_test_features_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    count_errors = (predictions.long() != my_test_target_.long()).sum().item()\n",
    "    return count_errors / my_test_features_.size(0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homemade framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 200\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 10\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:27.434627\n",
      "Loss: 1.6570 on final epoch: 200. Train error: 9.20000%, Test error: 17.60000%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class, p_dropout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, train_features, train_target, criterion, optimizer, num_epochs, batch_size, LRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train homemade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: \n",
      "\tLinear layer shape: [196, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 10]\n",
      "\tSoftmax function\n",
      "\tMSE\n",
      "Before training: Epoch: 0, Train Error: 87.8000%,        Test Error: 89.8000%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 66.1000%,        Test Error: 69.2000%, Loss  87.9086\n",
      "Epoch: 31, Train Error: 6.4000%,        Test Error: 14.7000%, Loss  11.4993\n",
      "Epoch: 61, Train Error: 3.7000%,        Test Error: 13.1000%, Loss  7.0031\n",
      "Epoch: 91, Train Error: 2.4000%,        Test Error: 12.7000%, Loss  5.1125\n",
      "Epoch: 121, Train Error: 3.0000%,        Test Error: 13.3000%, Loss  4.5845\n",
      "Epoch: 151, Train Error: 0.7000%,        Test Error: 12.9000%, Loss  3.8625\n",
      "Epoch: 181, Train Error: 0.5000%,        Test Error: 12.6000%, Loss  0.9094\n",
      "\n",
      "Training time: 0:00:11.374471\n",
      "After training: Epoch: 199, Train Error: 0.3000%,        Test Error: 12.7000%, Loss  0.6062\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy array\n",
    "train_features_np, train_target_np = train_features.numpy(), train_target.numpy()\n",
    "test_features_np, test_target_np = test_features.numpy(), test_target.numpy()\n",
    "\n",
    "# Build the model\n",
    "Model = NN.Sequential([NN.Linear(input_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=False)\n",
    "\n",
    "NN.train_homemade_model(Model, num_epochs, train_features_np, train_target_np, test_features_np, test_target_np, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
