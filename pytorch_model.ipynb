{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import os\n",
    "size = 1000\n",
    "\n",
    "def mnist_to_pairs(nb, input, target):\n",
    "    input = torch.functional.F.avg_pool2d(input, kernel_size = 2)\n",
    "    a = torch.randperm(input.size(0))\n",
    "    a = a[:2 * nb].view(nb, 2)\n",
    "    input = torch.cat((input[a[:, 0]], input[a[:, 1]]), 1)\n",
    "    classes = target[a]\n",
    "    target = (classes[:, 0] <= classes[:, 1]).long()\n",
    "    return input, target, classes\n",
    "\n",
    "def generate_pair_sets(nb):\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_input = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_input = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "\n",
    "    return mnist_to_pairs(nb, train_input, train_target) + \\\n",
    "           mnist_to_pairs(nb, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:55: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:45: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "C:\\Users\\antho\\Anaconda3\\envs\\venv_torch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "size = 1000\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(size)\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable((train_classes))\n",
    "test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14]) torch.Size([1000]) torch.Size([1000, 2])\n",
      "torch.Size([1000, 2, 14, 14]) torch.Size([1000]) torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, train_target.shape, train_classes.shape)\n",
    "print(test_input.shape, test_target.shape, test_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_10 = torch.Tensor(10, 2*1000, 14*14)\n",
    "test_target_10 = torch.Tensor(10, 1000)\n",
    "test_classes_10 = torch.Tensor(10, 2*1000)\n",
    "for i in range(1,10):\n",
    "    train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(size)\n",
    "    test_input, test_target, test_classes = Variable(test_input), Variable(test_target), Variable(test_classes)\n",
    "    test_input_10[i,:,:] = test_input.reshape([2000,196])\n",
    "    test_target_10[i,:] = test_target\n",
    "    test_classes_10[i,:] = test_classes.reshape([2000])\n",
    "my_train_input = train_input.reshape([2000,196])\n",
    "my_train_classes = train_classes.reshape([2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_input[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_classes[i][0]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_input[i][1], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_classes[i][1]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First neural net\n",
    "Train the model on all the 2000 images in train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# number of epoch\n",
    "num_epochs = 25\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 100\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.004\n",
    "# hidden size\n",
    "hidden_size = 500\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU() \n",
    "        self.softmax = nn.Softmax()\n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)  \n",
    "        self.layer3 = nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        outputs = self.layer1(x)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.layer2(outputs)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.relu(outputs)\n",
    "        outputs = self.layer3(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, my_train_input_, my_train_classes_, criterion_, optimizer_,num_epochs_,batch_size_,learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(my_train_input_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = my_train_input_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = my_train_classes_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, my_train_input_, my_train_classes_))\n",
    "        test_ = []\n",
    "        # getting test errors on 10 different samples\n",
    "        for i in range(1,10):\n",
    "            test_.append(test_accuracy(model_, test_input_10[i,:,:], test_classes_10[i,:]))\n",
    "        # getting the test error as the mean of the 10 we got\n",
    "        test_error.append(sum(test_) / len(test_))\n",
    "    # getting end time and training time\n",
    "    end_time = datetime.datetime.now()\n",
    "    training_time = end_time - start_time\n",
    "    print ('Loss: {:.4f} on epoch: {}, train error: {:.5f}, avg test error on 10 different samples: {:.5f}'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_input_, my_test_classes_):\n",
    "    total = my_test_input_.size(0)\n",
    "    outputs = model_(my_test_input_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    well_predicted_count = (predictions.long() == my_test_classes_.long()).sum().item()\n",
    "\n",
    "    return 1 - well_predicted_count / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1150 on epoch: 25, train error: 0.01950, avg test error on 10 different samples: 0.10633\n"
     ]
    }
   ],
   "source": [
    "batch_size, hidden_size, learning_rate, LRD, p_dropout, HS = 20, 500, 0.004, True, 0, 50\n",
    "\n",
    "model = NeuralNet(input_size, HS, num_class, p_dropout)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, my_train_input, my_train_classes, criterion, optimizer,num_epochs,batch_size,LRD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
