{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_sets():\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_features = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "    train_features = torch.functional.F.avg_pool2d(train_features, kernel_size = 2)\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_features = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "    test_features = torch.functional.F.avg_pool2d(test_features, kernel_size = 2)\n",
    "\n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_features, train_target, test_features, test_target = generate_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 14, 14]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 14, 14]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "train_perm = torch.randperm(train_features.size(0))\n",
    "idx = train_perm[:data_size]\n",
    "train_features = train_features[idx].reshape([data_size, train_features.size(2)**2])\n",
    "train_target = train_target[idx]\n",
    "\n",
    "test_perm = torch.randperm(test_features.size(0))\n",
    "idx = test_perm[:data_size]\n",
    "test_features = test_features[idx].reshape([data_size, test_features.size(2)**2])\n",
    "test_target = test_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196]) torch.Size([1000])\n",
      "torch.Size([1000, 196]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def normalize(tensor):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return tensor.sub_(mean).div_(std)\n",
    "\n",
    "normalize(train_features)\n",
    "normalize(test_features)\n",
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_features[i].reshape([14, 14]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_target[i]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.ReLU = torch.nn.ReLU() \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = torch.nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.ReLU(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, train_features_, train_target_, criterion_, optimizer_, num_epochs_, batch_size_, learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(train_features_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = train_features_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, train_features_, train_target_))\n",
    "        test_error.append(test_accuracy(model_, test_features, test_target))\n",
    "    # getting end time and training time\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    print('Loss: {:.4f} on final epoch: {}. Train error: {:.5f}%, Test error: {:.5f}%'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_features_, my_test_target_):\n",
    "    outputs = model_(my_test_features_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    count_errors = (predictions.long() != my_test_target_.long()).sum().item()\n",
    "    return count_errors / my_test_features_.size(0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homemade framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 200\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 10\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pytorch model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class, p_dropout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, train_features, train_target, criterion, optimizer, num_epochs, batch_size, LRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train homemade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: \n",
      "\tLinear layer shape: [196, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 128]\n",
      "\tLeakyReLU activation\n",
      "\tLinear layer shape: [128, 10]\n",
      "\tSoftmax function\n",
      "\tMSE\n",
      "Before training: Epoch: 0, Train Error: 90.1000%,        Test Error: 89.3000%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 63.3000%,        Test Error: 65.9000%, Loss  88.7268\n",
      "Epoch: 31, Train Error: 6.5000%,        Test Error: 15.1000%, Loss  10.8222\n",
      "Epoch: 61, Train Error: 3.0000%,        Test Error: 14.1000%, Loss  9.6130\n",
      "Epoch: 91, Train Error: 2.0000%,        Test Error: 14.2000%, Loss  6.7343\n",
      "Epoch: 121, Train Error: 1.4000%,        Test Error: 15.1000%, Loss  4.0039\n",
      "Epoch: 151, Train Error: 0.3000%,        Test Error: 14.1000%, Loss  0.6325\n",
      "Epoch: 181, Train Error: 0.3000%,        Test Error: 14.1000%, Loss  0.5141\n",
      "\n",
      "Training time: 0:00:09.883563\n",
      "After training: Epoch: 199, Train Error: 89.7000%,        Test Error: 91.5000%, Loss  nan\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy array\n",
    "train_features_np, train_target_np = train_features.numpy(), train_target.numpy()\n",
    "test_features_np, test_target_np = test_features.numpy(), test_target.numpy()\n",
    "\n",
    "# Build the model\n",
    "Model = NN.Sequential([NN.Linear(input_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, hidden_size), NN.LeakyReLU(),\n",
    "                       NN.Linear(hidden_size, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=False)\n",
    "\n",
    "NN.train_homemade_model(Model, num_epochs, train_features_np, train_target_np, test_features_np, test_target_np, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = 2\n",
    "train_features_tmp, train_target_tmp = train_features_np.reshape([1000,14,14])[0:nb], train_target_np[0:nb]\n",
    "test_features_tmp, test_target_tmp = test_features_np.reshape([1000,14,14])[0:nb], test_target_np[0:nb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train features shape: (2, 14, 14) \n",
      "train target shape: (2,),      \n",
      "test features shape: (2, 14, 14),\n",
      "test target shape: (2,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train features shape: {} \\ntrain target shape: {},\\\n",
    "      \\ntest features shape: {},\\ntest target shape: {}\".format(train_features_tmp.shape, train_target_tmp.shape,\n",
    "                                                             test_features_tmp.shape, test_target_tmp.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: Linear in green, Activation in blue, Loss in magenta, Softmax in red, Flatten in Gray, Convolution in Cyan\n",
      "\u001b[36m\tConvolution feature maps: 16, kernel size: (16, 3, 3)\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation\u001b[0m\n",
      "\u001b[36m\tConvolution feature maps: 16, kernel size: (16, 3, 3)\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation\u001b[0m\n",
      "\u001b[37m\tFlatten function\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [100, 10]\u001b[0m\n",
      "\u001b[31m\tSoftmax function\u001b[0m\n",
      "\u001b[35m\tMSE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "Model = NN.Sequential([NN.Convolution(), NN.LeakyReLU(),\n",
    "                       NN.Convolution(), NN.LeakyReLU(),\n",
    "                       NN.Flatten(),\n",
    "                       NN.Linear(100, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  3,  4],\n",
       "       [ 5,  6,  7,  8],\n",
       "       [ 9, 10, 11, 12],\n",
       "       [13, 14, 15, 16]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12], [13,14,15,16]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel = np.array([[1,2,3], [4,5,6], [7,8,9]])\n",
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(kernel.reshape([np.prod(kernel.shape)]), kernel.reshape([np.prod(kernel.shape)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "patches = np.asarray([x[j:2*j+kernel.shape[0], k:2*k+kernel.shape[0]] for j in range(x.shape[0]//2) for k in range(x.shape[1]//2)])\n",
    "#patches = patches.reshape([patches.shape[0]//2, patches.shape[0]//2, kernel.shape[0]*kernel.shape[1]])\n",
    "patches = patches.reshape([patches.shape[0], kernel.shape[0]*kernel.shape[1]])\n",
    "patches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_repeat = np.repeat(kernel.reshape([1, np.prod(kernel.shape)]), patches.shape[0], axis=0)\n",
    "kernel_repeat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.asarray([np.matmul(kernel_repeat[i,:], patches[i,:]) for i in range(kernel_repeat.shape[0])])\n",
    "result = result.reshape([result.shape[0]//2, result.shape[0]//2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[348, 393],\n",
       "       [528, 573]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
