{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pair_sets():\n",
    "    data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "    if data_dir is None:\n",
    "        data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_features = train_set.train_data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.train_labels\n",
    "    train_features = torch.functional.F.avg_pool2d(train_features, kernel_size = 2)\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_features = test_set.test_data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.test_labels\n",
    "    test_features = torch.functional.F.avg_pool2d(test_features, kernel_size = 2)\n",
    "\n",
    "    return train_features, train_target, test_features, test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "train_features, train_target, test_features, test_target = generate_pair_sets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 1, 14, 14]) torch.Size([60000])\n",
      "torch.Size([10000, 1, 14, 14]) torch.Size([10000])\n"
     ]
    }
   ],
   "source": [
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 1000\n",
    "train_perm = torch.randperm(train_features.size(0))\n",
    "idx = train_perm[:data_size]\n",
    "train_features = train_features[idx].reshape([data_size, train_features.size(2)**2])\n",
    "train_target = train_target[idx]\n",
    "\n",
    "test_perm = torch.randperm(test_features.size(0))\n",
    "idx = test_perm[:data_size]\n",
    "test_features = test_features[idx].reshape([data_size, test_features.size(2)**2])\n",
    "test_target = test_target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 196]) torch.Size([1000])\n",
      "torch.Size([1000, 196]) torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "def normalize(tensor):\n",
    "    mean, std = tensor.mean(), tensor.std()\n",
    "    return tensor.sub_(mean).div_(std)\n",
    "\n",
    "normalize(train_features)\n",
    "normalize(test_features)\n",
    "print(train_features.shape, train_target.shape)\n",
    "print(test_features.shape, test_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(test_features[i].reshape([14, 14]), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Value: {}\".format(test_target[i]))  \n",
    "    plt.tight_layout()\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Fully connected neural network\n",
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_class, dropout_p):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size) \n",
    "        self.ReLU = torch.nn.ReLU() \n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, hidden_size)  \n",
    "        self.fc3 = torch.nn.Linear(hidden_size, num_class) \n",
    "        self.dropout = torch.nn.Dropout(dropout_p) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.ReLU(self.fc1(x))\n",
    "        x = self.ReLU(self.fc2(x))\n",
    "        x = self.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train each model\n",
    "def train_model(model_, train_features_, train_target_, criterion_, optimizer_, num_epochs_, batch_size_, learning_rate_decay):\n",
    "    # getting start time of train to get the train time at the end thanks to \"end_time\"\n",
    "    start_time = datetime.datetime.now()\n",
    "    # list to get train and test errors at each epoch\n",
    "    train_error = []\n",
    "    test_error = []\n",
    "    # train function\n",
    "    # Learning rate decay can be enabled or disabled than to an input in the function's parameters\n",
    "    if learning_rate_decay:\n",
    "        lambda_ = lambda epoch: 0.8 ** epoch\n",
    "        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer_, lr_lambda=lambda_)\n",
    "    for epoch in range(1, num_epochs_+1):\n",
    "        # using technique of mini batch (size of the batch in the function's parameters)\n",
    "        for i in range(int(len(train_features_)/batch_size_)):  \n",
    "            # getting images and labels in right format\n",
    "            images = train_features_.narrow(0,i*batch_size_,batch_size_)\n",
    "            labels = train_target_.narrow(0,i*batch_size_,batch_size_)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model_(images)\n",
    "            loss = criterion_(outputs, labels)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        if learning_rate_decay:\n",
    "            scheduler.step()\n",
    "        # getting train error at each epoch\n",
    "        train_error.append(test_accuracy(model_, train_features_, train_target_))\n",
    "        test_error.append(test_accuracy(model_, test_features, test_target))\n",
    "    # getting end time and training time\n",
    "    training_time = datetime.datetime.now() - start_time\n",
    "    print('Training time: {}'.format(training_time))\n",
    "    print('Loss: {:.4f} on final epoch: {}. Train error: {:.5f}%, Test error: {:.5f}%'.format(loss.item(),epoch,train_error[-1],test_error[-1]))\n",
    "    return train_error, test_error, training_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model_, my_test_features_, my_test_target_):\n",
    "    outputs = model_(my_test_features_)\n",
    "    _, predictions = torch.max(outputs.data, 1)\n",
    "    count_errors = (predictions.long() != my_test_target_.long()).sum().item()\n",
    "    return count_errors / my_test_features_.size(0) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homemade framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 200\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 10\n",
    "# number of pixels in the image \n",
    "input_size = 196\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 10\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:00:27.724748\n",
      "Loss: 1.4706 on final epoch: 200. Train error: 11.60000%, Test error: 19.60000%\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNet(input_size, hidden_size, num_class, p_dropout)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "train_error, test_error, train_time = train_model(model, train_features, train_target, criterion, optimizer, num_epochs, batch_size, LRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train homemade model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: Linear in green, Activation in blue, Loss in magenta, Softmax in red, Flatten in Gray, Convolution in Cyan, Batch_normalization in Black\n",
      "\u001b[32m\tLinear layer shape: [196, 128]\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation\u001b[0m\n",
      "\u001b[39m\tBatch normalization function\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [128, 128]\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation\u001b[0m\n",
      "\u001b[39m\tBatch normalization function\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [128, 10]\u001b[0m\n",
      "\u001b[31m\tSoftmax function\u001b[0m\n",
      "\u001b[35m\tMSE\u001b[0m\n",
      "Before training: Epoch: 0, Train Error: 92.2000%,        Test Error: 92.0000%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 23.2000%,        Test Error: 30.7000%, Loss  73.4514\n",
      "Epoch: 31, Train Error: 4.8000%,        Test Error: 14.2000%, Loss  0.3119\n",
      "Epoch: 61, Train Error: 4.0000%,        Test Error: 13.8000%, Loss  0.0942\n",
      "Epoch: 91, Train Error: 3.8000%,        Test Error: 13.5000%, Loss  0.0618\n",
      "Epoch: 121, Train Error: 3.7000%,        Test Error: 13.4000%, Loss  0.0462\n",
      "Epoch: 151, Train Error: 3.5000%,        Test Error: 13.3000%, Loss  0.0371\n",
      "Epoch: 181, Train Error: 3.5000%,        Test Error: 13.4000%, Loss  0.0309\n",
      "\n",
      "Training time: 0:00:20.165181\n",
      "After training: Epoch: 199, Train Error: 3.4000%,        Test Error: 13.2000%, Loss  0.0280\n"
     ]
    }
   ],
   "source": [
    "# convert data to numpy array\n",
    "train_features_np, train_target_np = train_features.numpy(), train_target.numpy()\n",
    "test_features_np, test_target_np = test_features.numpy(), test_target.numpy()\n",
    "\n",
    "# Build the model\n",
    "Model = NN.Sequential([NN.Linear(input_size, hidden_size), NN.LeakyReLU(), NN.Batch_normalization(),\n",
    "                       NN.Linear(hidden_size, hidden_size), NN.LeakyReLU(), NN.Batch_normalization(),\n",
    "                       NN.Linear(hidden_size, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "Model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "Model.print(print_color=True)\n",
    "\n",
    "NN.train_homemade_model(Model, num_epochs, train_features_np, train_target_np, test_features_np, test_target_np, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.print_current_results(0, Model, train_features_np, train_target_np,\n",
    "                         test_features_np, test_target_np, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
