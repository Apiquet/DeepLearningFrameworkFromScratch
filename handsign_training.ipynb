{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DB.db_manager import DBManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs, train_labels, test_imgs, test_labels = DBManager.load_data(\"C:/Users/antho/Documents/GitHub/data/handsigns/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# displaying samples of data\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.imshow(train_imgs[i].reshape([train_imgs.shape[2],\n",
    "                                      train_imgs.shape[3]]),\n",
    "               cmap='gray', interpolation='none')\n",
    "    plt.title(\"Label: {}\".format(train_labels[i]), color='g')  \n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homemade_framework import framework as NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epoch\n",
    "num_epochs = 5\n",
    "# batch size to compute mini-batch\n",
    "batch_size = 100\n",
    "# number of pixels in the image \n",
    "input_size = 28*28\n",
    "# number of possible digit: 0 to 9 \n",
    "num_class = 7\n",
    "# small step to find a minima\n",
    "learning_rate = 0.01\n",
    "# hidden size\n",
    "hidden_size = 128\n",
    "# p dropout\n",
    "p_dropout = 0\n",
    "# learning rate decay\n",
    "LRD = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: Linear in green, Activation in blue, Loss in magenta, Softmax in red, Flatten in Gray, Convolution in Cyan, BatchNormalization in Black, MaxPooling2D in Yellow, AveragePooling2D in highlight\n",
      "\u001b[36m\tConvolution feature maps: 2, kernel size: (2, 1, 3, 3)\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation, a=0.01\u001b[0m\n",
      "\u001b[33m\tMax Pooling layer, size: 2\u001b[0m\n",
      "\u001b[36m\tConvolution feature maps: 2, kernel size: (2, 2, 3, 3)\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation, a=0.01\u001b[0m\n",
      "\u001b[37m\tFlatten function\u001b[0m\n",
      "\u001b[39m\tBatch normalization function: a=1, b=0\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [242, 128]\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation, a=0.01\u001b[0m\n",
      "\u001b[39m\tBatch normalization function: a=1, b=0\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [128, 7]\u001b[0m\n",
      "\u001b[31m\tSoftmax function\u001b[0m\n",
      "\u001b[35m\tMSE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "kernel_size = 3\n",
    "in_channels = 1\n",
    "out_channels = 2\n",
    "data_size = train_imgs.shape[2]\n",
    "nb_maxpool = 1\n",
    "out_first_conv = (data_size - kernel_size + 1) // (2*nb_maxpool) - kernel_size + 1\n",
    "\n",
    "# Build the model\n",
    "cnn_model = NN.Sequential([NN.Convolution(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
    "                           NN.LeakyReLU(), NN.MaxPooling2D(2),\n",
    "                           NN.Convolution(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size),\n",
    "                           NN.LeakyReLU(), NN.Flatten(), NN.BatchNorm(),\n",
    "                           NN.Linear((out_first_conv**2)*out_channels, hidden_size), NN.LeakyReLU(), NN.BatchNorm(),\n",
    "                           NN.Linear(hidden_size, num_class), NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "cnn_model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "cnn_model.print(print_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: Epoch: 0, Train Error: 88.4694%,        Test Error: 87.1429%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 5.6122%,        Test Error: 9.2857%, Loss  50.8701\n",
      "Epoch: 2, Train Error: 2.1429%,        Test Error: 4.2857%, Loss  8.4040\n",
      "Epoch: 3, Train Error: 0.9184%,        Test Error: 2.6190%, Loss  2.5709\n",
      "Epoch: 4, Train Error: 0.6122%,        Test Error: 1.6667%, Loss  1.2786\n",
      "Epoch: 5, Train Error: 0.5102%,        Test Error: 1.6667%, Loss  0.7325\n",
      "\n",
      "Training time: 0:01:57.286228\n",
      "After training: Epoch: 4, Train Error: 0.5102%,        Test Error: 1.6667%, Loss  0.7325\n"
     ]
    }
   ],
   "source": [
    "NN.train(cnn_model, num_epochs, train_imgs, train_labels, test_imgs, test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32069"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.getParametersCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.save(\"../handsigns_models/cnn/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model.load(\"../handsigns_models/cnn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 53,  1,  0,  0,  0,  0],\n",
       "       [ 0,  0, 57,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0, 58,  0,  0,  0],\n",
       "       [ 0,  4,  0,  0, 65,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 54,  0],\n",
       "       [ 0,  0,  0,  0,  1,  0, 60]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = NN.get_inferences(cnn_model, test_imgs)\n",
    "NN.get_confusion_matrix(test_pred, test_labels, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs_flatten = train_imgs.reshape([train_imgs.shape[0], np.prod(train_imgs.shape[1:])])\n",
    "test_imgs_flatten = test_imgs.reshape([test_imgs.shape[0], np.prod(test_imgs.shape[1:])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model description: Linear in green, Activation in blue, Loss in magenta, Softmax in red, Flatten in Gray, Convolution in Cyan, BatchNormalization in Black, MaxPooling2D in Yellow, AveragePooling2D in highlight\n",
      "\u001b[32m\tLinear layer shape: [784, 128]\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation, a=0.01\u001b[0m\n",
      "\u001b[39m\tBatch normalization function: a=1, b=0\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [128, 128]\u001b[0m\n",
      "\u001b[34m\tLeakyReLU activation, a=0.01\u001b[0m\n",
      "\u001b[39m\tBatch normalization function: a=1, b=0\u001b[0m\n",
      "\u001b[32m\tLinear layer shape: [128, 7]\u001b[0m\n",
      "\u001b[31m\tSoftmax function\u001b[0m\n",
      "\u001b[35m\tMSE\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "fcn_model = NN.Sequential([NN.Linear(input_size, hidden_size),\n",
    "                           NN.LeakyReLU(), NN.BatchNorm(),\n",
    "                           NN.Linear(hidden_size, hidden_size),\n",
    "                           NN.LeakyReLU(), NN.BatchNorm(),\n",
    "                           NN.Linear(hidden_size, num_class),\n",
    "                           NN.Softmax()], NN.LossMSE())\n",
    "# Set the learning rate\n",
    "fcn_model.set_Lr(learning_rate)\n",
    "# Print model's parameters\n",
    "fcn_model.print(print_color=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: Epoch: 0, Train Error: 92.3469%,        Test Error: 90.7143%, Loss  0.0000\n",
      "Epoch: 1, Train Error: 0.4082%,        Test Error: 0.4762%, Loss  33.1755\n",
      "Epoch: 2, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.8515\n",
      "Epoch: 3, Train Error: 0.2041%,        Test Error: 1.1905%, Loss  0.6595\n",
      "Epoch: 4, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.2221\n",
      "Epoch: 5, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0842\n",
      "Epoch: 6, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0602\n",
      "Epoch: 7, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0507\n",
      "Epoch: 8, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0445\n",
      "Epoch: 9, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0398\n",
      "Epoch: 10, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0362\n",
      "\n",
      "Training time: 0:00:00.386964\n",
      "After training: Epoch: 9, Train Error: 0.0000%,        Test Error: 0.2381%, Loss  0.0362\n"
     ]
    }
   ],
   "source": [
    "NN.train(fcn_model, num_epochs, train_imgs_flatten, train_labels,\n",
    "         test_imgs_flatten, test_labels, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117899"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcn_model.getParametersCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model.save(\"../handsigns_models/fcn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model.load(\"../handsigns_models/fcn/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = NN.get_inferences(fcn_model, test_imgs_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420, 784)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs_flatten.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  0,  0,  1,  0,  0,  0],\n",
       "       [ 0, 57,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0, 58,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 58,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0, 66,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 54,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0, 60]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN.get_confusion_matrix(test_pred, test_labels, num_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of a simple fully-connected net in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(tf.keras.Input(shape=(784,)))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Dense(hidden_size, activation='relu'))\n",
    "model.add(Dense(num_class, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 117,895\n",
      "Trainable params: 117,895\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([980, 1, 7]), TensorShape([980, 1, 784]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_tensor = tf.expand_dims(tf.convert_to_tensor(train_imgs_flatten), axis=1)\n",
    "train_labels_tensor = tf.expand_dims(tf.one_hot(tf.convert_to_tensor(train_labels), depth=7), axis=1)\n",
    "train_labels_tensor.shape, train_image_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 784) for input Tensor(\"input_1:0\", shape=(None, 784), dtype=float32), but it was called on an input with incompatible shape (None, 1, 784).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 784) for input Tensor(\"input_1:0\", shape=(None, 784), dtype=float32), but it was called on an input with incompatible shape (None, 1, 784).\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.5455 - accuracy: 0.5959\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 0s 1ms/step - loss: 1.0231 - accuracy: 0.9327\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 0s 805us/step - loss: 0.7666 - accuracy: 0.9561\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 0s 798us/step - loss: 0.5920 - accuracy: 0.9755\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 0s 864us/step - loss: 0.4855 - accuracy: 0.9816\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 0s 855us/step - loss: 0.4205 - accuracy: 0.9837\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 0s 809us/step - loss: 0.3727 - accuracy: 0.9898\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 0s 831us/step - loss: 0.3389 - accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 0s 831us/step - loss: 0.3118 - accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 0s 833us/step - loss: 0.2863 - accuracy: 0.9939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16c775b4b50>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_image_tensor, train_labels_tensor, epochs=num_epochs, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 6, 0, 6])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[10:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int64, numpy=array([1, 1, 6, 0, 6], dtype=int64)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(model(test_imgs_flatten[10:15]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\antho\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: models/tf_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('../handsigns_models/tf_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
